import os
import json
import shutil
import argparse

from pathlib import Path
from pdf_craft.llm import LLM
from pdf_craft import OCRLevel, PDFPageExtractor, ExtractedTableFormat,generate_epub_file, TableRender, LaTeXRender
from pdf_craft.analysers import analyse


def main() -> None:
  parser = argparse.ArgumentParser(description="PDF åˆ†æå’Œè½¬æ¢å·¥å…·")
  parser.add_argument("--file", required=True, help="è¦å¤„ç†çš„ PDF æ–‡ä»¶è·¯å¾„")
  parser.add_argument("--translate", action="store_true", help="å¯ç”¨ä¸­æ–‡ç¿»è¯‘åŠŸèƒ½")
  parser.add_argument("--target-lang", default="zh-CN", help="ç›®æ ‡ç¿»è¯‘è¯­è¨€ï¼ˆé»˜è®¤ï¼šzh-CNï¼‰")
  parser.add_argument("--translation-mode", choices=["replace", "dual", "separate"],
                     default="replace", help="ç¿»è¯‘æ¨¡å¼ï¼šreplace(å•è¯­æ›¿æ¢ï¼Œé»˜è®¤), dual(åŒè¯­), separate(åˆ†ç¦»)")
  parser.add_argument("--restore", action="store_true", help="æ¢å¤ä¹‹å‰çš„å¤„ç†è¿›åº¦ï¼Œä¸æ¸…ç†ç°æœ‰æ–‡ä»¶")
  args = parser.parse_args()

  # è¯»å–é…ç½®å¹¶æ ¹æ®å‘½ä»¤è¡Œå‚æ•°è°ƒæ•´
  config = _read_format_json()
  if args.translate:
    config["translation"]["enabled"] = True
    config["translation"]["target_language"] = args.target_lang
    config["translation"]["mode"] = args.translation_mode
    mode_desc = {
      "replace": "å•è¯­æ›¿æ¢",
      "dual": "åŒè¯­å¯¹ç…§",
      "separate": "åˆ†ç¦»è¾“å‡º"
    }
    print(f"âœ“ ç¿»è¯‘åŠŸèƒ½å·²å¯ç”¨ - ç›®æ ‡è¯­è¨€: {args.target_lang}, æ¨¡å¼: {mode_desc.get(args.translation_mode, args.translation_mode)}")

  # æ¢å¤æ¨¡å¼æç¤º
  if args.restore:
    print("ğŸ”„ æ¢å¤æ¨¡å¼å·²å¯ç”¨ - å°†ä»ä¹‹å‰çš„è¿›åº¦ç»§ç»­å¤„ç†")
    print("   - ä¸ä¼šæ¸…ç†ç°æœ‰çš„ output å’Œ analysing æ–‡ä»¶å¤¹")
    print("   - å°†è·³è¿‡å·²å®Œæˆçš„å¤„ç†æ­¥éª¤")

    # æ£€æŸ¥ç°æœ‰è¿›åº¦
    _check_existing_progress()

  # å¦‚æœå¯ç”¨ç¿»è¯‘ï¼Œéœ€è¦ä¼ é€’ç¿»è¯‘é…ç½®ç»™åˆ†æå™¨
  translation_config = config.get("translation") if args.translate else None

  # åˆ›å»º LLM å®ä¾‹
  llm_config = {k: v for k, v in config.items() if k != "translation"}
  llm = LLM(**llm_config)

  extractor=PDFPageExtractor(
    device="cuda",
    ocr_level=OCRLevel.OncePerLayout,
    extract_formula=True, # å¼€å¯å…¬å¼è¯†åˆ«
    extract_table_format=ExtractedTableFormat.HTML, # å¼€å¯è¡¨æ ¼è¯†åˆ«ï¼ˆä»¥ HTML æ ¼å¼ä¿å­˜ï¼‰
    model_dir_path=str(_project_dir_path("models")),
    debug_dir_path=str(_project_dir_path("analysing") / "plot"),
  )

  # æ ¹æ®æ˜¯å¦æ¢å¤æ¨¡å¼å†³å®šæ˜¯å¦æ¸…ç†æ–‡ä»¶å¤¹
  clean_folders = not args.restore

  # åˆ†æPDFï¼Œä¼ é€’ç¿»è¯‘é…ç½®
  analyse(
    llm=llm,
    pdf_page_extractor=extractor,
    correction=True,
    pdf_path=Path(args.file),
    analysing_dir_path=_project_dir_path("analysing", clean=clean_folders),
    output_path=_project_dir_path("output", clean=clean_folders),
    translation_config=translation_config,  # ä¼ é€’ç¿»è¯‘é…ç½®
  )

  # ç”ŸæˆEPUBæ–‡ä»¶
  if args.translate:
    if args.translation_mode == "replace":
      epub_filename = f"translated_{args.target_lang}.epub"
    elif args.translation_mode == "dual":
      epub_filename = "bilingual.epub"
    else:  # separate
      epub_filename = "output.epub"
  else:
    epub_filename = "output.epub"

  # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨EPUBæ–‡ä»¶ï¼ˆæ¢å¤æ¨¡å¼ä¸‹ï¼‰
  epub_path = _project_dir_path("output") / epub_filename
  if args.restore and epub_path.exists():
    print(f"ğŸ“š å‘ç°å·²å­˜åœ¨çš„EPUBæ–‡ä»¶: {epub_filename}")
    user_input = input("æ˜¯å¦é‡æ–°ç”ŸæˆEPUBæ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
    if user_input not in ['y', 'yes']:
      print(f"âœ“ è·³è¿‡EPUBç”Ÿæˆï¼Œä½¿ç”¨ç°æœ‰æ–‡ä»¶: {epub_filename}")
      return

  generate_epub_file(
    from_dir_path=_project_dir_path("output"), # æ¥è‡ªä¸Šä¸€æ­¥åˆ†ææ‰€äº§ç”Ÿçš„æ–‡ä»¶å¤¹
    epub_file_path=epub_path, # ç”Ÿæˆçš„ EPUB æ–‡ä»¶ä¿å­˜è·¯å¾„
    table_render=TableRender.HTML, # è¡¨æ ¼æ¸²æŸ“æ¨¡å¼
    latex_render=LaTeXRender.SVG, # å…¬å¼æ¸²æŸ“æ¨¡å¼
  )

  if args.translate:
    print(f"âœ“ ç¿»è¯‘å®Œæˆï¼EPUBæ–‡ä»¶å·²ç”Ÿæˆ: {epub_filename}")
  else:
    print(f"âœ“ å¤„ç†å®Œæˆï¼EPUBæ–‡ä»¶å·²ç”Ÿæˆ: {epub_filename}")

def _check_existing_progress():
  """æ£€æŸ¥ç°æœ‰çš„å¤„ç†è¿›åº¦"""
  base_path = Path(__file__).parent
  analysing_path = base_path / "analysing"
  output_path = base_path / "output"

  print("ğŸ“Š æ£€æŸ¥ç°æœ‰è¿›åº¦:")

  # æ£€æŸ¥ analysing æ–‡ä»¶å¤¹ä¸­çš„å„ä¸ªé˜¶æ®µ
  stages = [
    ("ocr", "OCRè¯†åˆ«"),
    ("sequence", "åºåˆ—æå–"),
    ("correction", "å†…å®¹æ ¡æ­£"),
    ("contents", "ç›®å½•æå–"),
    ("chapter", "ç« èŠ‚ç”Ÿæˆ"),
    ("reference", "å¼•ç”¨å¤„ç†")
  ]

  for stage_dir, stage_name in stages:
    stage_path = analysing_path / stage_dir
    if stage_path.exists() and any(stage_path.iterdir()):
      print(f"   âœ… {stage_name}: å‘ç°å·²å¤„ç†çš„æ–‡ä»¶")
    else:
      print(f"   â¸ï¸  {stage_name}: æœªå¼€å§‹æˆ–æœªå®Œæˆ")

  # æ£€æŸ¥ output æ–‡ä»¶å¤¹
  if output_path.exists() and any(output_path.iterdir()):
    print(f"   âœ… è¾“å‡ºæ–‡ä»¶: å‘ç°å·²ç”Ÿæˆçš„æ–‡ä»¶")
    # åˆ—å‡ºç°æœ‰çš„è¾“å‡ºæ–‡ä»¶
    for file in output_path.iterdir():
      if file.is_file():
        print(f"      - {file.name}")
  else:
    print(f"   â¸ï¸  è¾“å‡ºæ–‡ä»¶: æœªç”Ÿæˆ")

def _read_format_json() -> dict:
  path = os.path.join(__file__, "..", "format.json")
  path = os.path.abspath(path)
  with open(path, mode="r", encoding="utf-8") as file:
    return json.load(file)

def _project_dir_path(name: str, clean: bool = False) -> Path:
  path = Path(__file__) / ".." / name
  path = path.resolve()
  if clean:
    if path.exists():
      print(f"ğŸ—‘ï¸  æ¸…ç†æ–‡ä»¶å¤¹: {name}")
      shutil.rmtree(path, ignore_errors=True)
  path.mkdir(parents=True, exist_ok=True)
  return path

if __name__ == "__main__":
  main()