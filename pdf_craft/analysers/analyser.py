from os import PathLike
from pathlib import Path
from typing import Optional, Dict, Any

from ..llm import LLM
from ..pdf import PDFPageExtractor

from .ocr import generate_ocr_pages
from .sequence import extract_sequences
from .correction import correct
from .contents import extract_contents
from .chapter import generate_chapters
from .reference import generate_chapters_with_footnotes
from .output import output


def analyse(
    llm: LLM,
    pdf_page_extractor: PDFPageExtractor,
    pdf_path: PathLike,
    analysing_dir_path: PathLike,
    output_path: PathLike,
    correction: bool = False,
    translation_config: Optional[Dict[str, Any]] = None,
  ) -> None:

  max_data_tokens = 4096
  analysing_dir_path = Path(analysing_dir_path)
  ocr_path = analysing_dir_path / "ocr"
  assets_path = analysing_dir_path / "assets"
  sequence_path = analysing_dir_path / "sequence"
  correction_path = analysing_dir_path / "correction"
  contents_path = analysing_dir_path / "contents"
  chapter_path = analysing_dir_path / "chapter"
  reference_path = analysing_dir_path / "reference"

  # æ˜¾ç¤ºç¿»è¯‘æ¨¡å¼ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
  if translation_config and translation_config.get("enabled"):
    mode_desc = {
      "replace": "å•è¯­æ›¿æ¢",
      "dual": "åŒè¯­å¯¹ç…§",
      "separate": "åˆ†ç¦»è¾“å‡º"
    }
    mode = translation_config.get("mode", "replace")
    print(f"âœ“ ç¿»è¯‘æ¨¡å¼å·²æ¿€æ´» - ç›®æ ‡è¯­è¨€: {translation_config.get('target_language', 'zh-CN')}, æ¨¡å¼: {mode_desc.get(mode, mode)}")
    print("ğŸ“ æ³¨æ„ï¼šç¿»è¯‘å°†åœ¨ç« èŠ‚ç”Ÿæˆé˜¶æ®µè¿›è¡Œï¼Œä»¥ç¡®ä¿æ ¼å¼å…¼å®¹æ€§")

  generate_ocr_pages(
    extractor=pdf_page_extractor,
    pdf_path=Path(pdf_path),
    ocr_path=ocr_path,
    assets_path=assets_path,
  )
  extract_sequences(
    llm=llm,
    workspace=sequence_path,
    ocr_path=ocr_path,
    max_data_tokens=max_data_tokens,
  )
  sequence_output_path = sequence_path / "output"

  if correction:
    sequence_output_path = correct(
      llm=llm,
      workspace=correction_path,
      text_path=sequence_output_path / "text",
      footnote_path=sequence_output_path / "footnote",
      max_data_tokens=max_data_tokens,
    )

  contents = extract_contents(
    llm=llm,
    workspace=contents_path,
    sequence_path=sequence_output_path / "text",
    max_data_tokens=max_data_tokens,
  )

  # åªåœ¨ç« èŠ‚ç”Ÿæˆé˜¶æ®µå¯ç”¨ç¿»è¯‘åŒ…è£…å™¨
  chapter_llm = llm
  if translation_config and translation_config.get("enabled"):
    chapter_llm = _create_translation_llm_wrapper(llm, translation_config)
    print("ğŸ”„ åœ¨ç« èŠ‚ç”Ÿæˆé˜¶æ®µå¯ç”¨ç¿»è¯‘åŠŸèƒ½...")

  chapter_output_path, contents = generate_chapters(
    llm=chapter_llm,
    contents=contents,
    sequence_path=sequence_output_path / "text",
    workspace_path=chapter_path,
    max_request_tokens=max_data_tokens,
  )
  footnote_sequence_path = sequence_output_path / "footnote"

  if footnote_sequence_path.exists():
    chapter_output_path = generate_chapters_with_footnotes(
      chapter_path=chapter_output_path,
      footnote_sequence_path=footnote_sequence_path,
      workspace_path=reference_path,
    )

  output(
    contents=contents,
    output_path=Path(output_path),
    chapter_output_path=chapter_output_path,
    assets_path=assets_path,
  )


class _TranslationLLMWrapper:
  """LLM åŒ…è£…å™¨ï¼Œåœ¨åŸæœ‰åŠŸèƒ½åŸºç¡€ä¸Šæ·»åŠ ç¿»è¯‘åŠŸèƒ½"""

  def __init__(self, original_llm: LLM, translation_config: Dict[str, Any]):
    self.original_llm = original_llm
    self.translation_config = translation_config
    self.target_language = translation_config.get("target_language", "zh-CN")
    self.mode = translation_config.get("mode", "replace")

  def __getattr__(self, name):
    """ä»£ç†æ‰€æœ‰å…¶ä»–æ–¹æ³•åˆ°åŸå§‹ LLM"""
    return getattr(self.original_llm, name)

  def request(self, input_data, parser):
    """é‡å†™ request æ–¹æ³•ï¼Œæ·»åŠ ç¿»è¯‘åŠŸèƒ½"""
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¿»è¯‘ï¼ˆåŸºäºè¾“å…¥å†…å®¹åˆ¤æ–­ï¼‰
    if self._should_translate(input_data):
      # ä¿®æ”¹è¾“å…¥ï¼Œæ·»åŠ ç¿»è¯‘æŒ‡ä»¤
      modified_input = self._add_translation_instruction(input_data)
      # è°ƒç”¨åŸå§‹ LLM
      result = self.original_llm.request(modified_input, parser)
      # å¤„ç†ç¿»è¯‘ç»“æœ
      return self._process_translation_result(result)
    else:
      # ä¸éœ€è¦ç¿»è¯‘çš„å†…å®¹ç›´æ¥è°ƒç”¨åŸå§‹ LLM
      return self.original_llm.request(input_data, parser)

  def _should_translate(self, input_data) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ç¿»è¯‘æ­¤è¾“å…¥"""
    # æ›´ä¿å®ˆçš„ç¿»è¯‘ç­–ç•¥ï¼šåªç¿»è¯‘æ˜æ˜¾çš„æ–‡æœ¬å†…å®¹
    input_str = str(input_data)
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§é‡æ–‡æœ¬å†…å®¹ï¼Œä¸”ä¸æ˜¯ XML æˆ–ç»“æ„åŒ–æ•°æ®
    has_text_content = len(input_str) > 200
    has_translation_keywords = any(keyword in input_str.lower() for keyword in
                                  ['paragraph', 'chapter', 'content', 'text'])
    is_not_xml = '<' not in input_str[:100]  # ç®€å•æ£€æŸ¥æ˜¯å¦ä¸º XML

    return has_text_content and has_translation_keywords and is_not_xml

  def _add_translation_instruction(self, input_data):
    """ä¸ºè¾“å…¥æ·»åŠ ç¿»è¯‘æŒ‡ä»¤"""
    if hasattr(input_data, '__iter__') and not isinstance(input_data, str):
      # å¦‚æœæ˜¯æ¶ˆæ¯åˆ—è¡¨ï¼Œä¿®æ”¹æœ€åä¸€ä¸ªç”¨æˆ·æ¶ˆæ¯
      modified_input = list(input_data)
      if modified_input and hasattr(modified_input[-1], 'content'):
        original_content = modified_input[-1].content

        # æ ¹æ®ç¿»è¯‘æ¨¡å¼ç”Ÿæˆä¸åŒçš„æŒ‡ä»¤
        if self.mode == "replace":
          translation_instruction = f"""
è¯·å®ŒæˆåŸæœ‰ä»»åŠ¡ï¼Œå¹¶å°†æ‰€æœ‰æ–‡æœ¬å†…å®¹ç¿»è¯‘ä¸º{self.target_language}ã€‚

é‡è¦ï¼šè¯·ç›´æ¥è¿”å›ç¿»è¯‘åçš„ç»“æœï¼Œä¸è¦åŒ…å«åŸæ–‡ã€‚ä¿æŒç›¸åŒçš„ç»“æ„å’Œæ ¼å¼ã€‚

åŸå§‹è¯·æ±‚ï¼š
{original_content}
"""
        elif self.mode == "dual":
          translation_instruction = f"""
è¯·å®ŒæˆåŸæœ‰ä»»åŠ¡ï¼Œå¹¶å°†æ‰€æœ‰æ–‡æœ¬å†…å®¹ç¿»è¯‘ä¸º{self.target_language}ã€‚

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å›ç»“æœï¼š

## åŸå§‹åˆ†æç»“æœ
{{åŸæœ‰çš„åˆ†æç»“æœ}}

## {self.target_language}ç¿»è¯‘
{{ç¿»è¯‘åçš„å†…å®¹ï¼Œä¿æŒç›¸åŒçš„ç»“æ„å’Œæ ¼å¼}}

åŸå§‹è¯·æ±‚ï¼š
{original_content}
"""
        else:  # separate mode
          translation_instruction = f"""
è¯·å®ŒæˆåŸæœ‰ä»»åŠ¡ï¼ŒåŒæ—¶ç”Ÿæˆ{self.target_language}ç¿»è¯‘ç‰ˆæœ¬ã€‚

è¯·åˆ†åˆ«è¿”å›åŸæ–‡å’Œç¿»è¯‘ç‰ˆæœ¬ï¼Œä¿æŒç›¸åŒçš„ç»“æ„å’Œæ ¼å¼ã€‚

åŸå§‹è¯·æ±‚ï¼š
{original_content}
"""

        modified_input[-1].content = translation_instruction
        return modified_input

    return input_data

  def _process_translation_result(self, result):
    """å¤„ç†åŒ…å«ç¿»è¯‘çš„ç»“æœ"""
    # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å¤„ç†ç¿»è¯‘ç»“æœ
    # ç›®å‰ç®€å•è¿”å›åŸç»“æœï¼Œè®©ä¸‹æ¸¸å¤„ç†
    return result


def _create_translation_llm_wrapper(llm: LLM, translation_config: Dict[str, Any]) -> LLM:
  """åˆ›å»ºæ”¯æŒç¿»è¯‘çš„ LLM åŒ…è£…å™¨"""
  return _TranslationLLMWrapper(llm, translation_config)
